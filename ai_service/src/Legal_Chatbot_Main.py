from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from pydantic import BaseModel
import requests, os
from typing import List, Dict, Optional
import asyncio
from concurrent.futures import ThreadPoolExecutor
import json
from untils.internal_analysis import generate_internal_report
from untils.compliance import run_compliance_check 
from untils.text_extract import extract_text_from_pdf_bytes, extract_text_from_docx 
from ocr.ocr_utils_main import ocr_image

GEMINI_API_KEY = "" 

MODEL_NAME_COMPLEX = "gemini-2.5-pro"
MODEL_NAME_CHAT = "gemini-2.5-flash" 
# GEMINI_API_URL = f"https://generativelanguage.googleapis.com/v1beta/models/{MODEL_NAME_COMPLEX}:generateContent?key={GEMINI_API_KEY}"
# GEMINI_CHAT_URL = f"https://generativelanguage.googleapis.com/v1beta/models/{MODEL_NAME_CHAT}:generateContent?key={GEMINI_API_KEY}"


app = FastAPI()
executor = ThreadPoolExecutor()
chat_sessions: Dict[str, List[Dict[str, str]]] = {}

@app.get("/")
def read_root():
    return {"message": "AI Legal Contract & Law Chatbot is running ğŸš€"}

def call_gemini_api(messages: List[Dict[str, str]], model_url: str):
    
    gemini_contents = []
    system_instruction = None
    
    for msg in messages:
        # TÃ¡ch System message ra khá»i contents
        if msg['role'] == 'system':
            system_instruction = msg['content']
            continue
            
        role = 'model' if msg['role'] == 'assistant' else 'user'
        gemini_contents.append({
            "role": role,
            "parts": [{"text": msg['content']}]
        })

    payload = {
        "contents": gemini_contents,
    }
    
    if system_instruction:
        payload["systemInstruction"] = {"parts": [{"text": system_instruction}]}

    headers = {
        "Content-Type": "application/json"
    }
    
    res = requests.post(model_url, headers=headers, json=payload, timeout=180)
    res.raise_for_status()
    
    result = res.json()
    
    answer = result.get("candidates", [{}])[0].get("content", {}).get("parts", [{}])[0].get("text", "")
    return answer

#PHÃ‚N TÃCH Há»¢P Äá»’NG
#api phÃ¢n tÃ­ch
@app.post("/analyze_contract")
async def analyze_contract(file: UploadFile = File(...)):
    
    os.makedirs("uploads", exist_ok=True)
    file_path = os.path.join("uploads", file.filename)

    try:
        with open(file_path, "wb") as f:
            f.write(await file.read())
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Lá»—i khi lÆ°u file: {e}")

    contract_text = ""
    if file.filename.endswith(".pdf"):
        try:
            with open(file_path, "rb") as f:
                file_bytes = f.read()
            contract_text = extract_text_from_pdf_bytes(file_bytes)
        except Exception:
            raise HTTPException(status_code=400, detail="Lá»—i trÃ­ch xuáº¥t vÄƒn báº£n tá»« file PDF.")
            
    elif file.filename.endswith(".docx"):
        try:
            contract_text = extract_text_from_docx(file_path)
        except Exception:
            raise HTTPException(status_code=400, detail="Lá»—i trÃ­ch xuáº¥t vÄƒn báº£n tá»« file DOCX.")
    else:
        raise HTTPException(status_code=400, detail="Chá»‰ há»— trá»£ file PDF hoáº·c DOCX.")

    if not contract_text.strip():
        raise HTTPException(status_code=400, detail="KhÃ´ng thá»ƒ Ä‘á»c ná»™i dung há»£p Ä‘á»“ng (file rá»—ng).")

    contract_excerpt = contract_text[:8000].rsplit('.', 1)[0] + '.' if len(contract_text) > 8000 else contract_text

    system_prompt = "Báº¡n lÃ  chuyÃªn gia phÃ¡p lÃ½ Viá»‡t Nam, am hiá»ƒu Bá»™ luáº­t Lao Ä‘á»™ng 2019."
    user_prompt = f"""
    DÆ°á»›i Ä‘Ã¢y lÃ  ná»™i dung há»£p Ä‘á»“ng lao Ä‘á»™ng:

    --- Há»¢P Äá»’NG ---
    {contract_excerpt}

    HÃ£y thá»±c hiá»‡n cÃ¡c yÃªu cáº§u sau:
    1. TÃ³m táº¯t ná»™i dung há»£p Ä‘á»“ng ngáº¯n gá»n, dá»… hiá»ƒu.
    2. ÄÃ¡nh giÃ¡ quyá»n lá»£i vÃ  nghÄ©a vá»¥ cá»§a ngÆ°á»i lao Ä‘á»™ng trong há»£p Ä‘á»“ng nÃ y.
    3. PhÃ¢n tÃ­ch xem cÃ³ Ä‘iá»u khoáº£n nÃ o cÃ³ dáº¥u hiá»‡u vi pháº¡m Bá»™ luáº­t Lao Ä‘á»™ng 2019 khÃ´ng.
    4. Äá» xuáº¥t cÃ¡ch chá»‰nh sá»­a Ä‘á»ƒ há»£p Ä‘á»“ng phÃ¹ há»£p phÃ¡p luáº­t hÆ¡n.
    TrÃ¬nh bÃ y báº±ng tiáº¿ng Viá»‡t dá»… hiá»ƒu vÃ  sá»­ dá»¥ng format Markdown.
    """

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt},
    ]

    try:
        loop = asyncio.get_event_loop()
        api_url = f"https://generativelanguage.googleapis.com/v1beta/models/{MODEL_NAME_COMPLEX}:generateContent?key={GEMINI_API_KEY}"
        answer = await loop.run_in_executor(executor, call_gemini_api, messages, api_url)
    except requests.exceptions.HTTPError as http_err:
        error_detail = f"Lá»—i HTTP khi gá»i Gemini API: {http_err}. Kiá»ƒm tra API Key vÃ  URL."
        raise HTTPException(status_code=http_err.response.status_code if http_err.response else 500, detail=error_detail)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Lá»—i khi gá»i Gemini API: {e}")

    return {"summary": answer,
            "content": contract_text.strip()
            }


def call_gemini_api_sync(messages: List[Dict[str, str]]):
    
    model_url = f"https://generativelanguage.googleapis.com/v1beta/models/{MODEL_NAME_CHAT}:generateContent?key={GEMINI_API_KEY}"
    
    return call_gemini_api(messages, model_url)

# API chat (há»i Ä‘Ã¡p luáº­t)
@app.post("/chat")
async def chat_with_ai(message: str = Form(...), session_id: str = Form("default")):

    message = message.strip()
    if not message:
        raise HTTPException(status_code=400, detail="Tin nháº¯n khÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ trá»‘ng.")

    if session_id not in chat_sessions:
        chat_sessions[session_id] = [
            {
                "role": "system",
                "content": (
                    "Báº¡n lÃ  chuyÃªn gia phÃ¡p lÃ½ Viá»‡t Nam, am hiá»ƒu **duy nháº¥t vá» Bá»™ luáº­t Lao Ä‘á»™ng 2019**. "
                    "Nhiá»‡m vá»¥ cá»§a báº¡n chá»‰ lÃ  tráº£ lá»i cÃ¡c cÃ¢u há»i liÃªn quan Ä‘áº¿n Luáº­t Lao Ä‘á»™ng. "
                    "Náº¿u ngÆ°á»i dÃ¹ng há»i vá» báº¥t ká»³ chá»§ Ä‘á» nÃ o khÃ¡c (vÃ­ dá»¥: cÃ´ng thá»©c náº¥u Äƒn, tin tá»©c, lá»‹ch sá»­, toÃ¡n há»c, luáº­t dÃ¢n sá»±, luáº­t hÃ¬nh sá»±, v.v.), "
                    "báº¡n pháº£i tráº£ lá»i **chÃ­nh xÃ¡c** cÃ¢u sau: 'Xin lá»—i, tÃ´i chá»‰ cÃ³ thá»ƒ há»— trá»£ cÃ¡c váº¥n Ä‘á» liÃªn quan Ä‘áº¿n Bá»™ luáº­t Lao Ä‘á»™ng 2019. Vui lÃ²ng há»i tÃ´i vá» luáº­t lao Ä‘á»™ng. "
                    "'.Náº¿u mÃ  ngÆ°á»i dÃ¹ng nháº¯n lÃ  hi, chÃ o thÃ¬ tráº£ lá»i **chÃ­nh xÃ¡c** cÃ¢u sau: 'ChÃ o, tÃ´i cÃ³ thá»ƒ giÃºp gÃ¬ cho báº¡n vá» luáº­t Lao Äá»™ng khÃ´ng ?' " # THAY Äá»”I Lá»šN
                    
                    "HÃ£y chÃº Ã½ phÃ¢n tÃ­ch cÃ¡c thÃ´ng tin Ä‘Æ°á»£c cung cáº¥p trong pháº§n 'PHÃ‚N TÃCH Ná»˜I Bá»˜' vÃ  'Äiá»u luáº­t liÃªn quan' Ä‘á»ƒ tráº£ lá»i. "
                    "Khi tráº£ lá»i, hÃ£y trÃ¬nh bÃ y NGáº®N Gá»ŒN, XÃšC TÃCH, dá»… hiá»ƒu vá»›i ngÆ°á»i dÃ¢n. "
                    "Chá»‰ dáº«n Ä‘iá»u luáº­t khi tháº­t sá»± cáº§n thiáº¿t."
                )
            }
        ]

    # PhÃ¢n tÃ­ch Ná»™i bá»™: Nháº­n dáº¡ng cÃ¡c thá»±c thá»ƒ phÃ¡p lÃ½ trong cÃ¢u há»i ngÆ°á»i dÃ¹ng
    internal_report = generate_internal_report(message)



    rag_prompt = f"""
    CÃ¢u há»i ngÆ°á»i dÃ¹ng: {message}

    {internal_report}
    
 

    YÃªu cáº§u:
    - Dá»±a vÃ o cÃ¡c Ä‘iá»u luáº­t vÃ  thÃ´ng tin phÃ¢n tÃ­ch ná»™i bá»™ Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i ngÆ°á»i dÃ¹ng.
    - Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t dá»… hiá»ƒu, khÃ´ng láº·p láº¡i nguyÃªn vÄƒn luáº­t, vÃ  khÃ´ng cáº§n láº·p láº¡i "Äiá»u luáº­t liÃªn quan" hay "PHÃ‚N TÃCH Ná»˜I Bá»˜".
    """
    
    chat_sessions[session_id].append({"role": "user", "content": rag_prompt})

    try:
        loop = asyncio.get_event_loop()
        answer = await loop.run_in_executor(executor, call_gemini_api_sync, chat_sessions[session_id])
    except requests.exceptions.HTTPError as http_err:
        error_detail = f"Lá»—i HTTP khi gá»i Gemini API (Chat): {http_err}. Kiá»ƒm tra API Key vÃ  URL."
        raise HTTPException(
            status_code=http_err.response.status_code if http_err.response else 500,
            detail=error_detail,
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Lá»—i khi gá»i Gemini API (Chat): {e}")

    answer = answer.strip()
    # if len(answer) > 800:
    #     answer = answer[:800].rsplit('.', 1)[0] + "."

    chat_sessions[session_id].append({"role": "assistant", "content": answer})

    return {
        "session_id": session_id,
        "user_message": message,
        "ai_reply": answer,
        "internal_entities": internal_report.splitlines()[1:-1] if internal_report else [],
        "history_count": len(chat_sessions[session_id]),
    }

# API reset chat (xÃ³a lá»‹ch sá»­ phiÃªn)
@app.post("/reset_chat")
def reset_chat(session_id: str = Form("default")):
    if session_id in chat_sessions:
        del chat_sessions[session_id]
        return {"message": f"ÄÃ£ xÃ³a lá»‹ch sá»­ chat cá»§a phiÃªn {session_id}."}
    return {"message": "KhÃ´ng cÃ³ phiÃªn nÃ o Ä‘á»ƒ xÃ³a."}

@app.post("/ocr")
async def ocr_endpoint(files: List[UploadFile] = File(...)):
    contents = [await f.read() for f in files]

    try:
        texts = [ocr_image(file_bytes, enhance=False) for file_bytes in contents]
        ocr_text = "\n\n".join(texts).strip()
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Lá»—i khi OCR áº£nh: {e}")

    if not ocr_text:
        raise HTTPException(status_code=400, detail="KhÃ´ng thá»ƒ Ä‘á»c Ä‘Æ°á»£c vÄƒn báº£n tá»« áº£nh.")

    contract_excerpt = (
        ocr_text[:8000].rsplit('.', 1)[0] + '.'
        if len(ocr_text) > 8000
        else ocr_text
    )

    system_prompt = "Báº¡n lÃ  chuyÃªn gia phÃ¡p lÃ½ Viá»‡t Nam, am hiá»ƒu Bá»™ luáº­t Lao Ä‘á»™ng 2019."
    user_prompt = f"""
    DÆ°á»›i Ä‘Ã¢y lÃ  ná»™i dung há»£p Ä‘á»“ng Ä‘Æ°á»£c trÃ­ch xuáº¥t báº±ng OCR tá»« áº£nh:

    --- Ná»˜I DUNG Há»¢P Äá»’NG ---
    {contract_excerpt}

    HÃ£y thá»±c hiá»‡n cÃ¡c yÃªu cáº§u sau:
    1. TÃ³m táº¯t ngáº¯n gá»n ná»™i dung há»£p Ä‘á»“ng.
    2. ÄÃ¡nh giÃ¡ quyá»n lá»£i vÃ  nghÄ©a vá»¥ cá»§a ngÆ°á»i lao Ä‘á»™ng.
    3. XÃ¡c Ä‘á»‹nh xem cÃ³ Ä‘iá»u khoáº£n nÃ o cÃ³ dáº¥u hiá»‡u vi pháº¡m Bá»™ luáº­t Lao Ä‘á»™ng 2019 khÃ´ng.
    4. Äá» xuáº¥t chá»‰nh sá»­a Ä‘á»ƒ há»£p Ä‘á»“ng há»£p phÃ¡p hÆ¡n.
    TrÃ¬nh bÃ y báº±ng tiáº¿ng Viá»‡t dá»… hiá»ƒu vÃ  sá»­ dá»¥ng format Markdown.
    """

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt},
    ]

    try:
        loop = asyncio.get_event_loop()
        api_url = f"https://generativelanguage.googleapis.com/v1beta/models/{MODEL_NAME_COMPLEX}:generateContent?key={GEMINI_API_KEY}"
        analysis_result = await loop.run_in_executor(executor, call_gemini_api, messages, api_url)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Lá»—i khi phÃ¢n tÃ­ch há»£p Ä‘á»“ng: {e}")

    return {
        "message": "OCR vÃ  phÃ¢n tÃ­ch há»£p Ä‘á»“ng thÃ nh cÃ´ng!",
        "ocr_text": ocr_text,
        "analysis": analysis_result
    }

class ContractChatRequest(BaseModel):
    """
    Äá»‹nh nghÄ©a Pydantic model cho JSON payload
    """
    prompt: str
    context: str
    chat_history: Optional[List[Dict[str, str]]] = []

@app.post("/chat_with_context")
async def chat_with_contract_context(request: ContractChatRequest):
    """
    Nháº­n cÃ¢u há»i (prompt) vÃ  ngá»¯ cáº£nh (context) tá»« backend Node.js
    vÃ  tráº£ lá»i dá»±a trÃªn ngá»¯ cáº£nh Ä‘Ã³.
    """
    
    system_prompt = f"""
    Báº¡n lÃ  trá»£ lÃ½ phÃ¡p lÃ½ AI. Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  tráº£ lá»i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng
    CHá»ˆ Dá»°A TRÃŠN ngá»¯ cáº£nh há»£p Ä‘á»“ng Ä‘Ã£ Ä‘Æ°á»£c phÃ¢n tÃ­ch dÆ°á»›i Ä‘Ã¢y.
    
    --- NGá»® Cáº¢NH Há»¢P Äá»’NG ÄÃƒ PHÃ‚N TÃCH ---
    {request.context}
    --- Káº¾T THÃšC NGá»® Cáº¢NH ---

    Quy táº¯c tráº£ lá»i:
    - Chá»‰ tráº£ lá»i dá»±a vÃ o thÃ´ng tin trong "NGá»® Cáº¢NH Há»¢P Äá»’NG".
    - Náº¿u cÃ¢u há»i khÃ´ng thá»ƒ tráº£ lá»i báº±ng ngá»¯ cáº£nh, hÃ£y nÃ³i: "TÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin nÃ y trong há»£p Ä‘á»“ng Ä‘Ã£ phÃ¢n tÃ­ch."
    - Tráº£ lá»i ngáº¯n gá»n, táº­p trung, dá»… hiá»ƒu.
    """
    
    messages = [{"role": "system", "content": system_prompt}]
    
    if request.chat_history:
        for msg in request.chat_history:
            role = 'assistant' if msg['role'] == 'ai' else msg['role']
            messages.append({"role": role, "content": msg['content']})
            
    messages.append({"role": "user", "content": request.prompt})

    try:
        loop = asyncio.get_event_loop()
        answer = await loop.run_in_executor(executor, call_gemini_api_sync, messages)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Lá»—i khi gá»i Gemini API (Context Chat): {e}")

    return {"answer": answer.strip()}