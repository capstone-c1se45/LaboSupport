from fastapi import FastAPI, UploadFile, File,Form
from pydantic import BaseModel
import requests, os
from untils.text_extract import extract_text_from_pdf_bytes, extract_text_from_docx
from vector_store import query_law
from typing import List, Dict

app = FastAPI()

LM_STUDIO_API = "http://localhost:1234/v1/chat/completions"
MODEL_NAME = "openai/gpt-oss-20b"  


chat_sessions: Dict[str, List[Dict[str, str]]] = {}


@app.get("/")
def read_root():
    return {"message": "AI Legal Contract & Law Chatbot is running ğŸš€"}

def ask_model(messages):
    payload = {
        "model": MODEL_NAME,
        "messages": messages,
    }
    res = requests.post(LM_STUDIO_API, json=payload, timeout=120)
    res.raise_for_status()
    result = res.json()
    return result.get("choices", [{}])[0].get("message", {}).get("content", "")

# ğŸ“„ PHÃ‚N TÃCH Há»¢P Äá»’NG
@app.post("/analyze_contract")
async def analyze_contract(file: UploadFile = File(...)):
    os.makedirs("uploads", exist_ok=True)
    file_path = os.path.join("uploads", file.filename)

    # ğŸ“‚ LÆ°u file upload
    with open(file_path, "wb") as f:
        f.write(await file.read())

    # ğŸ“„ TrÃ­ch xuáº¥t ná»™i dung tá»« file PDF/DOCX
    if file.filename.endswith(".pdf"):
        with open(file_path, "rb") as f:
            file_bytes = f.read()
        contract_text = extract_text_from_pdf_bytes(file_bytes)
    elif file.filename.endswith(".docx"):
        contract_text = extract_text_from_docx(file_path)
    else:
        return {"error": "Chá»‰ há»— trá»£ file PDF hoáº·c DOCX."}

    # âŒ Náº¿u file rá»—ng hoáº·c khÃ´ng Ä‘á»c Ä‘Æ°á»£c
    if not contract_text.strip():
        return {"error": "KhÃ´ng thá»ƒ Ä‘á»c ná»™i dung há»£p Ä‘á»“ng."}

    # âœ‚ï¸ Cáº¯t gá»n ná»™i dung (trÃ¡nh input quÃ¡ dÃ i)
    contract_excerpt = contract_text[:1500].rsplit('.', 1)[0] + '.'

    # ğŸ§  Prompt Ä‘á»ƒ AI tá»± phÃ¢n tÃ­ch
    prompt = f"""
Báº¡n lÃ  chuyÃªn gia phÃ¡p lÃ½ Viá»‡t Nam, am hiá»ƒu Bá»™ luáº­t Lao Ä‘á»™ng 2019.

DÆ°á»›i Ä‘Ã¢y lÃ  ná»™i dung há»£p Ä‘á»“ng lao Ä‘á»™ng:

--- Há»¢P Äá»’NG ---
{contract_excerpt}

HÃ£y thá»±c hiá»‡n cÃ¡c yÃªu cáº§u sau:
1. TÃ³m táº¯t ná»™i dung há»£p Ä‘á»“ng ngáº¯n gá»n, dá»… hiá»ƒu.
2. ÄÃ¡nh giÃ¡ quyá»n lá»£i vÃ  nghÄ©a vá»¥ cá»§a ngÆ°á»i lao Ä‘á»™ng trong há»£p Ä‘á»“ng nÃ y.
3. PhÃ¢n tÃ­ch xem cÃ³ Ä‘iá»u khoáº£n nÃ o cÃ³ dáº¥u hiá»‡u vi pháº¡m Bá»™ luáº­t Lao Ä‘á»™ng 2019 khÃ´ng.
4. Äá» xuáº¥t cÃ¡ch chá»‰nh sá»­a Ä‘á»ƒ há»£p Ä‘á»“ng phÃ¹ há»£p phÃ¡p luáº­t hÆ¡n.
TrÃ¬nh bÃ y báº±ng tiáº¿ng Viá»‡t dá»… hiá»ƒu.
"""

    # ğŸš€ Gá»­i yÃªu cáº§u Ä‘áº¿n LM Studio
    payload = {
        "model": MODEL_NAME,
        "messages": [
            {"role": "system", "content": "Báº¡n lÃ  chuyÃªn gia phÃ¡p lÃ½ Viá»‡t Nam, am hiá»ƒu luáº­t lao Ä‘á»™ng."},
            {"role": "user", "content": prompt},
        ],
    }

    try:
        res = requests.post(LM_STUDIO_API, json=payload, timeout=180)
        res.raise_for_status()
        result = res.json()
        answer = result.get("choices", [{}])[0].get("message", {}).get("content", "")
    except Exception as e:
        return {"error": f"Lá»—i khi gá»i LM Studio API: {e}"}

    return {"summary": answer}


# ğŸ’¬ API chat (há»i Ä‘Ã¡p luáº­t)
@app.post("/chat")
async def chat_with_ai(message: str = Form(...), session_id: str = Form("default")):
    message = message.strip()
    if not message:
        return {"error": "Tin nháº¯n khÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ trá»‘ng."}

    # --- Khá»Ÿi táº¡o lá»‹ch sá»­ chat náº¿u chÆ°a cÃ³ ---
    if session_id not in chat_sessions:
        chat_sessions[session_id] = [
            {"role": "system", "content": "Báº¡n lÃ  chuyÃªn gia phÃ¡p lÃ½ Viá»‡t Nam, am hiá»ƒu Bá»™ luáº­t Lao Ä‘á»™ng 2019."}
        ]

    # --- TÃ¬m Ä‘iá»u luáº­t liÃªn quan ---
    related_laws = query_law(message, top_k=3)
    law_context = "\n\n".join(
        [f"Äiá»u {l['article_number']}: {l['article_title']}\n{l['content']}" for l in related_laws]
    )

    # --- Táº¡o prompt há»£p nháº¥t ---
    prompt = f"""
CÃ¢u há»i: {message}

--- Äiá»u luáº­t liÃªn quan ---
{law_context}

YÃªu cáº§u:
- Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t dá»… hiá»ƒu.
- Dáº«n Ä‘iá»u luáº­t náº¿u cÃ³.
- Náº¿u khÃ´ng cÃ³ quy Ä‘á»‹nh phÃ¹ há»£p, tráº£ lá»i: "KhÃ´ng cÃ³ quy Ä‘á»‹nh cá»¥ thá»ƒ trong Bá»™ luáº­t Lao Ä‘á»™ng 2019".
"""

    # --- ThÃªm vÃ o lá»‹ch sá»­ ---
    chat_sessions[session_id].append({"role": "user", "content": prompt})

    # --- Gá»i model ---
    try:
        answer = ask_model(chat_sessions[session_id])
    except Exception as e:
        return {"error": f"Lá»—i khi gá»i LM Studio API: {e}"}

    # --- LÆ°u pháº£n há»“i vÃ o lá»‹ch sá»­ ---
    chat_sessions[session_id].append({"role": "assistant", "content": answer})

    return {
        "session_id": session_id,
        "user_message": message,
        "ai_reply": answer,
        "related_articles": related_laws,
        "history_count": len(chat_sessions[session_id])
    }

# ğŸ”„ API reset chat (xÃ³a lá»‹ch sá»­ phiÃªn)
@app.post("/reset_chat")
def reset_chat(session_id: str = Form("default")):
    if session_id in chat_sessions:
        del chat_sessions[session_id]
        return {"message": f"ÄÃ£ xÃ³a lá»‹ch sá»­ chat cá»§a phiÃªn {session_id}."}
    return {"message": "KhÃ´ng cÃ³ phiÃªn nÃ o Ä‘á»ƒ xÃ³a."}
