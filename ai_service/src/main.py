from fastapi import FastAPI, UploadFile, File,Form
from pydantic import BaseModel
import requests, os
from untils.text_extract import extract_text_from_pdf_bytes, extract_text_from_docx
from vector_store import query_law
from typing import List, Dict

app = FastAPI()

LM_STUDIO_API = "http://localhost:1234/v1/chat/completions"
MODEL_NAME = "openai/gpt-oss-20b"  


chat_sessions: Dict[str, List[Dict[str, str]]] = {}


@app.get("/")
def read_root():
    return {"message": "AI Legal Contract & Law Chatbot is running ğŸš€"}

def ask_model(messages):
    payload = {
        "model": MODEL_NAME,
        "messages": messages,
    }
    res = requests.post(LM_STUDIO_API, json=payload, timeout=120)
    res.raise_for_status()
    result = res.json()
    return result.get("choices", [{}])[0].get("message", {}).get("content", "")

# ğŸ“„ PHÃ‚N TÃCH Há»¢P Äá»’NG
@app.post("/analyze_contract")
async def analyze_contract(file: UploadFile = File(...)):
    os.makedirs("uploads", exist_ok=True)
    file_path = os.path.join("uploads", file.filename)

    with open(file_path, "wb") as f:
        f.write(await file.read())

    if file.filename.endswith(".pdf"):
        with open(file_path, "rb") as f:
            file_bytes = f.read()
        contract_text = extract_text_from_pdf_bytes(file_bytes)
    elif file.filename.endswith(".docx"):
        contract_text = extract_text_from_docx(file_path)
    else:
        return {"error": "Chá»‰ há»— trá»£ file PDF hoáº·c DOCX."}

    if not contract_text.strip():
        return {"error": "KhÃ´ng thá»ƒ Ä‘á»c ná»™i dung há»£p Ä‘á»“ng."}

    related_laws = query_law(contract_text[:300])
    law_context = "\n\n".join(
        [f"Äiá»u {l['article_number']}: {l['article_title']}\n{l['content']}" for l in related_laws]
    )

    contract_excerpt = contract_text[:1200].rsplit('.', 1)[0] + '.'
    prompt = f"""
Báº¡n lÃ  chuyÃªn gia phÃ¡p lÃ½ Viá»‡t Nam.

--- Ná»™i dung há»£p Ä‘á»“ng ---
{contract_excerpt}

--- Äiá»u luáº­t liÃªn quan ---
{law_context}

HÃ£y:
1. TÃ³m táº¯t há»£p Ä‘á»“ng.
2. ÄÃ¡nh giÃ¡ quyá»n lá»£i & nghÄ©a vá»¥ ngÆ°á»i lao Ä‘á»™ng.
3. PhÃ¡t hiá»‡n vi pháº¡m Bá»™ luáº­t Lao Ä‘á»™ng 2019 (náº¿u cÃ³).
4. Gá»£i Ã½ Ä‘iá»u chá»‰nh há»£p lÃ½.
"""

    payload = {
        "model": MODEL_NAME,
        "messages": [
            {"role": "system", "content": "Báº¡n lÃ  chuyÃªn gia phÃ¡p lÃ½ Viá»‡t Nam, am hiá»ƒu Bá»™ luáº­t Lao Ä‘á»™ng 2019."},
            {"role": "user", "content": prompt},
        ],
    }

    try:
        res = requests.post(LM_STUDIO_API, json=payload, timeout=180)
        res.raise_for_status()
        result = res.json()
        answer = res
    except Exception as e:
        return {"error": f"Error calling LM Studio API: {str(e)}"}
    return {"summary": answer, "related_articles": related_laws}

# ğŸ’¬ API chat (há»i Ä‘Ã¡p luáº­t)
@app.post("/chat")
async def chat_with_ai(message: str = Form(...), session_id: str = Form("default")):
    message = message.strip()
    if not message:
        return {"error": "Tin nháº¯n khÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ trá»‘ng."}

    # --- Khá»Ÿi táº¡o lá»‹ch sá»­ chat náº¿u chÆ°a cÃ³ ---
    if session_id not in chat_sessions:
        chat_sessions[session_id] = [
            {"role": "system", "content": "Báº¡n lÃ  chuyÃªn gia phÃ¡p lÃ½ Viá»‡t Nam, am hiá»ƒu Bá»™ luáº­t Lao Ä‘á»™ng 2019."}
        ]

    # --- TÃ¬m Ä‘iá»u luáº­t liÃªn quan ---
    related_laws = query_law(message, top_k=3)
    law_context = "\n\n".join(
        [f"Äiá»u {l['article_number']}: {l['article_title']}\n{l['content']}" for l in related_laws]
    )

    # --- Táº¡o prompt há»£p nháº¥t ---
    prompt = f"""
CÃ¢u há»i: {message}

--- Äiá»u luáº­t liÃªn quan ---
{law_context}

YÃªu cáº§u:
- Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t dá»… hiá»ƒu.
- Dáº«n Ä‘iá»u luáº­t náº¿u cÃ³.
- Náº¿u khÃ´ng cÃ³ quy Ä‘á»‹nh phÃ¹ há»£p, tráº£ lá»i: "KhÃ´ng cÃ³ quy Ä‘á»‹nh cá»¥ thá»ƒ trong Bá»™ luáº­t Lao Ä‘á»™ng 2019".
"""

    # --- ThÃªm vÃ o lá»‹ch sá»­ ---
    chat_sessions[session_id].append({"role": "user", "content": prompt})

    # --- Gá»i model ---
    try:
        answer = ask_model(chat_sessions[session_id])
    except Exception as e:
        return {"error": f"Lá»—i khi gá»i LM Studio API: {e}"}

    # --- LÆ°u pháº£n há»“i vÃ o lá»‹ch sá»­ ---
    chat_sessions[session_id].append({"role": "assistant", "content": answer})

    return {
        "session_id": session_id,
        "user_message": message,
        "ai_reply": answer,
        "related_articles": related_laws,
        "history_count": len(chat_sessions[session_id])
    }

# ğŸ”„ API reset chat (xÃ³a lá»‹ch sá»­ phiÃªn)
@app.post("/reset_chat")
def reset_chat(session_id: str = Form("default")):
    if session_id in chat_sessions:
        del chat_sessions[session_id]
        return {"message": f"ÄÃ£ xÃ³a lá»‹ch sá»­ chat cá»§a phiÃªn {session_id}."}
    return {"message": "KhÃ´ng cÃ³ phiÃªn nÃ o Ä‘á»ƒ xÃ³a."}
