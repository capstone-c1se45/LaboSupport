from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from pydantic import BaseModel
import requests, os
from typing import List, Dict
import asyncio
from concurrent.futures import ThreadPoolExecutor
import json
from untils.text_extract import extract_text_from_pdf_bytes, extract_text_from_docx
from vector_store import query_law


GEMINI_API_KEY = "AIzaSyB0GGFyJLAytwEUGQk8ztw4nXjQQeAwEFU" 

MODEL_NAME_COMPLEX = "gemini-2.5-pro"
MODEL_NAME_CHAT = "gemini-2.5-flash" 
GEMINI_API_URL = f"https://generativelanguage.googleapis.com/v1beta/models/{MODEL_NAME_COMPLEX}:generateContent?key={GEMINI_API_KEY}"
GEMINI_CHAT_URL = f"https://generativelanguage.googleapis.com/v1beta/models/{MODEL_NAME_CHAT}:generateContent?key={GEMINI_API_KEY}"



app = FastAPI()
executor = ThreadPoolExecutor()
chat_sessions: Dict[str, List[Dict[str, str]]] = {}

@app.get("/")
def read_root():
    return {"message": "AI Legal Contract & Law Chatbot is running ğŸš€"}

def call_gemini_api(messages: List[Dict[str, str]], model_url: str):
    
    gemini_contents = []
    for msg in messages:
        role = 'model' if msg['role'] == 'assistant' else 'user'
        gemini_contents.append({
            "role": role,
            "parts": [{"text": msg['content']}]
        })

    payload = {
        "contents": gemini_contents,
    }
    
    system_instruction = next((msg['content'] for msg in messages if msg['role'] == 'system'), None)
    if system_instruction:
        payload["systemInstruction"] = {"parts": [{"text": system_instruction}]}
        payload["contents"] = [c for c in gemini_contents if c['role'] != 'system']

    headers = {
        "Content-Type": "application/json"
    }
    
    res = requests.post(model_url, headers=headers, json=payload, timeout=180)
    res.raise_for_status()
    
    result = res.json()
    
    answer = result.get("candidates", [{}])[0].get("content", {}).get("parts", [{}])[0].get("text", "")
    return answer

# ğŸ“„ PHÃ‚N TÃCH Há»¢P Äá»’NG (Sá»¬ Dá»¤NG GEMINI 2.5 PRO)
@app.post("/analyze_contract")
async def analyze_contract(file: UploadFile = File(...)):
    """API phÃ¢n tÃ­ch há»£p Ä‘á»“ng lao Ä‘á»™ng tá»« file PDF/DOCX"""
    
    os.makedirs("uploads", exist_ok=True)
    file_path = os.path.join("uploads", file.filename)

    try:
        with open(file_path, "wb") as f:
            f.write(await file.read())
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Lá»—i khi lÆ°u file: {e}")

    contract_text = ""
    if file.filename.endswith(".pdf"):
        try:
            with open(file_path, "rb") as f:
                file_bytes = f.read()
            contract_text = extract_text_from_pdf_bytes(file_bytes)
        except Exception:
             # Xá»­ lÃ½ lá»—i trÃ­ch xuáº¥t PDF
            raise HTTPException(status_code=400, detail="Lá»—i trÃ­ch xuáº¥t vÄƒn báº£n tá»« file PDF.")
            
    elif file.filename.endswith(".docx"):
        try:
            contract_text = extract_text_from_docx(file_path)
        except Exception:
            raise HTTPException(status_code=400, detail="Lá»—i trÃ­ch xuáº¥t vÄƒn báº£n tá»« file DOCX.")
    else:
        raise HTTPException(status_code=400, detail="Chá»‰ há»— trá»£ file PDF hoáº·c DOCX.")

    if not contract_text.strip():
        raise HTTPException(status_code=400, detail="KhÃ´ng thá»ƒ Ä‘á»c ná»™i dung há»£p Ä‘á»“ng (file rá»—ng).")

    contract_excerpt = contract_text[:8000].rsplit('.', 1)[0] + '.' if len(contract_text) > 8000 else contract_text

    system_prompt = "Báº¡n lÃ  chuyÃªn gia phÃ¡p lÃ½ Viá»‡t Nam, am hiá»ƒu Bá»™ luáº­t Lao Ä‘á»™ng 2019."
    user_prompt = f"""
    DÆ°á»›i Ä‘Ã¢y lÃ  ná»™i dung há»£p Ä‘á»“ng lao Ä‘á»™ng:

    --- Há»¢P Äá»’NG ---
    {contract_excerpt}

    HÃ£y thá»±c hiá»‡n cÃ¡c yÃªu cáº§u sau:
    1. TÃ³m táº¯t ná»™i dung há»£p Ä‘á»“ng ngáº¯n gá»n, dá»… hiá»ƒu.
    2. ÄÃ¡nh giÃ¡ quyá»n lá»£i vÃ  nghÄ©a vá»¥ cá»§a ngÆ°á»i lao Ä‘á»™ng trong há»£p Ä‘á»“ng nÃ y.
    3. PhÃ¢n tÃ­ch xem cÃ³ Ä‘iá»u khoáº£n nÃ o cÃ³ dáº¥u hiá»‡u vi pháº¡m Bá»™ luáº­t Lao Ä‘á»™ng 2019 khÃ´ng.
    4. Äá» xuáº¥t cÃ¡ch chá»‰nh sá»­a Ä‘á»ƒ há»£p Ä‘á»“ng phÃ¹ há»£p phÃ¡p luáº­t hÆ¡n.
    TrÃ¬nh bÃ y báº±ng tiáº¿ng Viá»‡t dá»… hiá»ƒu vÃ  sá»­ dá»¥ng format Markdown.
    """

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt},
    ]

    try:
        loop = asyncio.get_event_loop()
        api_url = f"https://generativelanguage.googleapis.com/v1beta/models/{MODEL_NAME_COMPLEX}:generateContent?key={GEMINI_API_KEY}"
        answer = await loop.run_in_executor(executor, call_gemini_api, messages, api_url)
    except requests.exceptions.HTTPError as http_err:
        error_detail = f"Lá»—i HTTP khi gá»i Gemini API: {http_err}. Kiá»ƒm tra API Key vÃ  URL."
        raise HTTPException(status_code=http_err.response.status_code if http_err.response else 500, detail=error_detail)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Lá»—i khi gá»i Gemini API: {e}")

    return {"summary": answer}


def call_gemini_api_sync(messages: List[Dict[str, str]]):
  
    model_url = f"https://generativelanguage.googleapis.com/v1beta/models/{MODEL_NAME_CHAT}:generateContent?key={GEMINI_API_KEY}"
    
    return call_gemini_api(messages, model_url)

# ğŸ’¬ API chat (há»i Ä‘Ã¡p luáº­t, sá»­ dá»¥ng GEMINI 2.5 FLASH)
@app.post("/chat")
async def chat_with_ai(message: str = Form(...), session_id: str = Form("default")):
    """API há»i Ä‘Ã¡p luáº­t - báº£n rÃºt gá»n, khÃ´ng dÃ¹ng query_law"""

    message = message.strip()
    if not message:
        raise HTTPException(status_code=400, detail="Tin nháº¯n khÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ trá»‘ng.")

    if session_id not in chat_sessions:
        chat_sessions[session_id] = [
            {
                "role": "system",
                "content": (
                    "Báº¡n lÃ  chuyÃªn gia phÃ¡p lÃ½ Viá»‡t Nam, am hiá»ƒu Bá»™ luáº­t Lao Ä‘á»™ng 2019. "
                    "Khi tráº£ lá»i, hÃ£y trÃ¬nh bÃ y NGáº®N Gá»ŒN, XÃšC TÃCH, dá»… hiá»ƒu vá»›i ngÆ°á»i dÃ¢n. "
                    "Chá»‰ dáº«n Ä‘iá»u luáº­t khi tháº­t sá»± cáº§n thiáº¿t."
                    "VÃ  Ä‘Æ°a ra nhá»¯ng Ä‘iá»u luáº­t liÃªn quan náº¿u cÃ³ thá»ƒ."
                )
            }
        ]

    # 2. ThÃªm cÃ¢u há»i ngÆ°á»i dÃ¹ng vÃ o lá»‹ch sá»­
    chat_sessions[session_id].append({"role": "user", "content": message})

    # 3. Gá»i model AI (qua Gemini hoáº·c LM Studio)
    try:
        loop = asyncio.get_event_loop()
        answer = await loop.run_in_executor(executor, call_gemini_api_sync, chat_sessions[session_id])
    except requests.exceptions.HTTPError as http_err:
        error_detail = f"Lá»—i HTTP khi gá»i Gemini API (Chat): {http_err}. Kiá»ƒm tra API Key vÃ  URL."
        raise HTTPException(
            status_code=http_err.response.status_code if http_err.response else 500,
            detail=error_detail,
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Lá»—i khi gá»i Gemini API (Chat): {e}")

    # 4. LÃ m gá»n pháº£n há»“i náº¿u quÃ¡ dÃ i
    answer = answer.strip()
    if len(answer) > 800:
        answer = answer[:800].rsplit('.', 1)[0] + "."

    # 5. LÆ°u pháº£n há»“i vÃ o lá»‹ch sá»­ há»™i thoáº¡i
    chat_sessions[session_id].append({"role": "assistant", "content": answer})

    # 6. Tráº£ káº¿t quáº£ cho client
    return {
        "session_id": session_id,
        "user_message": message,
        "ai_reply": answer,
        "history_count": len(chat_sessions[session_id]),
    }

# API reset chat (xÃ³a lá»‹ch sá»­ phiÃªn)
@app.post("/reset_chat")
def reset_chat(session_id: str = Form("default")):
    """API xÃ³a lá»‹ch sá»­ chat cá»§a má»™t phiÃªn"""
    if session_id in chat_sessions:
        del chat_sessions[session_id]
        return {"message": f"ÄÃ£ xÃ³a lá»‹ch sá»­ chat cá»§a phiÃªn {session_id}."}
    return {"message": "KhÃ´ng cÃ³ phiÃªn nÃ o Ä‘á»ƒ xÃ³a."}
